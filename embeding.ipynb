{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast  # for converting embeddings saved as strings back to arrays\n",
    "import openai # for calling the OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "import os # for getting API token from env variable OPENAI_API_KEY\n",
    "from scipy import spatial  # for calculating vector similarities for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de OpenAI\n",
    "openai.api_key = \"sk-proj-JEQe19qf1majBtkGMsubT3BlbkFJeGguQ7FTMjap1uVkFViu\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "MAX_TOKENS = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = EMBEDDING_MODEL) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_from_txt_files(directory: str, model: str = EMBEDDING_MODEL, max_tokens: int = 4096) -> pd.DataFrame:\n",
    "    texts = []\n",
    "    embeddings = []\n",
    "    filenames = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "                \n",
    "                # Split the text into manageable chunks\n",
    "                token_count = num_tokens(text, model=model)\n",
    "                if token_count > max_tokens:\n",
    "                    print(f\"Warning: File {filename} exceeds max token limit and will be truncated.\")\n",
    "                    text = text[:max_tokens]\n",
    "                \n",
    "                response = openai.Embedding.create(model=model, input=text)\n",
    "                embedding = response['data'][0]['embedding']\n",
    "                \n",
    "                texts.append(text)\n",
    "                embeddings.append(embedding)\n",
    "                filenames.append(filename)\n",
    "    \n",
    "    df = pd.DataFrame({\"text\": texts, \"embedding\": embeddings, \"filename\": filenames})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File Rutas.txt exceeds max token limit and will be truncated.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El comando \"Enviar mensaje al conductor\" permi...</td>\n",
       "      <td>[-0.02398996241390705, 0.00521461758762598, -0...</td>\n",
       "      <td>Conductores.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nEl dashboard en la plataforma de seguimiento...</td>\n",
       "      <td>[-0.023207632824778557, -0.0013814468402415514...</td>\n",
       "      <td>Dashboard.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nCreación y Gestión de Geocercas en el Sistem...</td>\n",
       "      <td>[-0.013827535323798656, 0.02504660375416279, 0...</td>\n",
       "      <td>Geocercas.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nLa plataforma de seguimiento ofrece diversas...</td>\n",
       "      <td>[-0.02603936940431595, 0.01353693287819624, -0...</td>\n",
       "      <td>Herramientas.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>En la pestaña de informes, se pueden crear inf...</td>\n",
       "      <td>[-0.00831671804189682, 0.004125538282096386, 0...</td>\n",
       "      <td>Informes.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Introducción a la plataforma:\\n\\nExplicación d...</td>\n",
       "      <td>[0.004063657484948635, 0.0053825052455067635, ...</td>\n",
       "      <td>Introducción a la plataforma.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nGestión de Notificaciones en el Sistema de S...</td>\n",
       "      <td>[-0.019962914288043976, 0.013457619585096836, ...</td>\n",
       "      <td>Notificaciones.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>La pestaña de recorridos en la plataforma de s...</td>\n",
       "      <td>[-0.012566705234348774, -0.012425732798874378,...</td>\n",
       "      <td>Recorridos.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Además de la pestaña Remolques, se pueden ver ...</td>\n",
       "      <td>[-0.017275424674153328, 0.00032052703318186104...</td>\n",
       "      <td>Remolques.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Algunos tipos de dispositivos soportan los com...</td>\n",
       "      <td>[-0.013809074647724628, 0.007888940162956715, ...</td>\n",
       "      <td>Rutas.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Introducción al Panel de Seguimiento:\\n\\nUbica...</td>\n",
       "      <td>[-0.008637646213173866, 0.013176645152270794, ...</td>\n",
       "      <td>Seguimiento.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>La pestaña de tareas en la plataforma de segui...</td>\n",
       "      <td>[-0.019789330661296844, -0.01101040467619896, ...</td>\n",
       "      <td>Tareas.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gestión de Unidades y Grupos en la Plataforma ...</td>\n",
       "      <td>[0.00523916631937027, 0.006938984617590904, 0....</td>\n",
       "      <td>Unidades.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gestión de Usuarios en la Plataforma de Seguim...</td>\n",
       "      <td>[-0.015079815872013569, 0.005064617842435837, ...</td>\n",
       "      <td>Usuarios.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   El comando \"Enviar mensaje al conductor\" permi...   \n",
       "1   \\nEl dashboard en la plataforma de seguimiento...   \n",
       "2   \\nCreación y Gestión de Geocercas en el Sistem...   \n",
       "3   \\nLa plataforma de seguimiento ofrece diversas...   \n",
       "4   En la pestaña de informes, se pueden crear inf...   \n",
       "5   Introducción a la plataforma:\\n\\nExplicación d...   \n",
       "6   \\nGestión de Notificaciones en el Sistema de S...   \n",
       "7   La pestaña de recorridos en la plataforma de s...   \n",
       "8   Además de la pestaña Remolques, se pueden ver ...   \n",
       "9   Algunos tipos de dispositivos soportan los com...   \n",
       "10  Introducción al Panel de Seguimiento:\\n\\nUbica...   \n",
       "11  La pestaña de tareas en la plataforma de segui...   \n",
       "12  Gestión de Unidades y Grupos en la Plataforma ...   \n",
       "13  Gestión de Usuarios en la Plataforma de Seguim...   \n",
       "\n",
       "                                            embedding  \\\n",
       "0   [-0.02398996241390705, 0.00521461758762598, -0...   \n",
       "1   [-0.023207632824778557, -0.0013814468402415514...   \n",
       "2   [-0.013827535323798656, 0.02504660375416279, 0...   \n",
       "3   [-0.02603936940431595, 0.01353693287819624, -0...   \n",
       "4   [-0.00831671804189682, 0.004125538282096386, 0...   \n",
       "5   [0.004063657484948635, 0.0053825052455067635, ...   \n",
       "6   [-0.019962914288043976, 0.013457619585096836, ...   \n",
       "7   [-0.012566705234348774, -0.012425732798874378,...   \n",
       "8   [-0.017275424674153328, 0.00032052703318186104...   \n",
       "9   [-0.013809074647724628, 0.007888940162956715, ...   \n",
       "10  [-0.008637646213173866, 0.013176645152270794, ...   \n",
       "11  [-0.019789330661296844, -0.01101040467619896, ...   \n",
       "12  [0.00523916631937027, 0.006938984617590904, 0....   \n",
       "13  [-0.015079815872013569, 0.005064617842435837, ...   \n",
       "\n",
       "                            filename  \n",
       "0                    Conductores.txt  \n",
       "1                      Dashboard.txt  \n",
       "2                      Geocercas.txt  \n",
       "3                   Herramientas.txt  \n",
       "4                       Informes.txt  \n",
       "5   Introducción a la plataforma.txt  \n",
       "6                 Notificaciones.txt  \n",
       "7                     Recorridos.txt  \n",
       "8                      Remolques.txt  \n",
       "9                          Rutas.txt  \n",
       "10                   Seguimiento.txt  \n",
       "11                        Tareas.txt  \n",
       "12                      Unidades.txt  \n",
       "13                      Usuarios.txt  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uso de la función\n",
    "directory = \"data\"\n",
    "df = create_embeddings_from_txt_files(directory)\n",
    "df.to_excel(\"vectores.xlsx\", index=False)\n",
    "df.to_csv(\"vectores.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtracion df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_and_select_files(directory: str) -> list:\n",
    "    files = [f for f in os.listdir(directory) if f.endswith(\".txt\")]\n",
    "    print(\"Archivos disponibles:\")\n",
    "    for i, file in enumerate(files, start=1):\n",
    "        print(f\"{i}. {file}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            selected_indices = input(\"Ingrese los números de los archivos que desea usar, separados por comas: \")\n",
    "            selected_indices = [int(i.strip()) for i in selected_indices.split(\",\")]\n",
    "            selected_files = [files[i - 1] for i in selected_indices]\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Entrada inválida. Por favor, ingrese números separados por comas.\")\n",
    "        except IndexError:\n",
    "            print(\"Uno o más números están fuera del rango. Por favor, inténtelo de nuevo.\")\n",
    "    \n",
    "    return selected_files\n",
    "\n",
    "def filter_dataframe_by_filenames(df: pd.DataFrame, filenames: list) -> pd.DataFrame:\n",
    "    filtered_df = df[df[\"filename\"].isin(filenames)].copy()\n",
    "    filtered_df.drop(columns=[\"filename\"], inplace=True)\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File Herramientas.txt exceeds max token limit and will be truncated.\n",
      "Warning: File Informes.txt exceeds max token limit and will be truncated.\n",
      "Archivos disponibles:\n",
      "1. Conductores y remolques.txt\n",
      "2. DAshboard.txt\n",
      "3. Geocercas.txt\n",
      "4. Herramientas Parte 1.txt\n",
      "5. Herramientas Parte 2.txt\n",
      "6. Herramientas.txt\n",
      "7. iDriveSafe.txt\n",
      "8. Informes.txt\n",
      "9. Introducción a la plataforma.txt\n",
      "10. Notificaciones.txt\n",
      "11. Panel de Informes lectura.txt\n",
      "12. Panel de informes(Ejecución).txt\n",
      "13. Panel Informes Creacion.txt\n",
      "14. Recorridos.txt\n",
      "15. Seguimiento.txt\n",
      "16. Sensolator.txt\n",
      "17. Tareas.txt\n",
      "18. Trackplayer.txt\n",
      "19. Unidades.txt\n",
      "20. Usuarios.txt\n",
      "                                                 text  \\\n",
      "2   \\nCreación y Gestión de Geocercas en el Sistem...   \n",
      "16  \\nLa pestaña de tareas en la plataforma de seg...   \n",
      "\n",
      "                                            embedding  \n",
      "2   [-0.013827535323798656, 0.02504660375416279, 0...  \n",
      "16  [-0.02037661150097847, -0.01038912683725357, -...  \n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "directory = \"data\"\n",
    "df = create_embeddings_from_txt_files(directory)\n",
    "\n",
    "selected_files = display_and_select_files(directory)\n",
    "filtered_df = filter_dataframe_by_filenames(df, selected_files)\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para clasificar las strings por relevancia usando embeddings\n",
    "def strings_ranked_by_relatedness(query: str, df: pd.DataFrame, top_n: int = 5, threshold: float = 0.76) -> list[tuple[str, float]]:\n",
    "    query_embedding_response = openai.Embedding.create(model=EMBEDDING_MODEL, input=query)\n",
    "    query_embedding = query_embedding_response['data'][0]['embedding']\n",
    "    strings_and_relatednesses = [(row[\"text\"], 1 - spatial.distance.cosine(query_embedding, row[\"embedding\"])) for _, row in df.iterrows()]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    valid_sections = [(s, r) for s, r in strings_and_relatednesses if r >= threshold]\n",
    "    \n",
    "    return valid_sections[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear el mensaje de consulta\n",
    "def query_message(query: str, df: pd.DataFrame, model: str, token_budget: int, threshold: float = 0.76) -> str:\n",
    "    valid_sections = strings_ranked_by_relatedness(query, df, threshold=threshold)\n",
    "    \n",
    "    if len(valid_sections) == 0:\n",
    "        return \"No cuento con esa información, por favor contactar a servicio a cliente.\"\n",
    "    \n",
    "    introduction = 'Use the below articles to answer the subsequent question. If the answer cannot be found in the articles, write \"I could not find an answer.\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string, relatedness in valid_sections:\n",
    "        next_article = f'\\n\\nText section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if num_tokens(message + next_article + question, model=model) > token_budget:\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para hacer la consulta a GPT\n",
    "def ask(query: str, df: pd.DataFrame, model: str = GPT_MODEL, token_budget: int = 4096 - 500, print_message: bool = False, threshold: float = 0.76) -> str:\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget, threshold=threshold)\n",
    "    if message == \"No cuento con esa información, por favor contactar a servicio a cliente.\":\n",
    "        return message\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions based on the provided articles.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages, temperature=0)\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_formatted_response(response: str) -> None:\n",
    "    formatted_response = response.replace(\"\\\\n\", \"\\n\")\n",
    "    formatted_response = formatted_response.replace('Wialon', 'Quamtum')\n",
    "    return formatted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una tarea es una acción automatizada que se puede programar en la plataforma de seguimiento para generar y enviar informes por correo electrónico, permitiendo configurar parámetros como la plantilla de informe, formato de envío, intervalos de informes, destinatarios, objeto del informe, nombre de la tarea, frecuencia de activación, fecha y hora de inicio, entre otros detalles. Una vez creada, la tarea se muestra en la lista de trabajo con su nombre, icono y descripción, y se pueden realizar acciones como activarla, desactivarla, ejecutarla como prueba, ver el número de ejecuciones, acceder a sus propiedades, copiarla o eliminarla.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "query = \"Que es una tarea\"\n",
    "response = ask(query, filtered_df, model=GPT_MODEL, print_message=False, threshold=0.76)\n",
    "print(print_formatted_response(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
